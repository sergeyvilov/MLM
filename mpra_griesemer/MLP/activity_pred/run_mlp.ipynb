{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20d5284-43a5-4c57-9006-828f0883a2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import sklearn.pipeline \n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/data/ouga/home/ag_gagneur/l_vilov/workspace/species-aware-DNA-LM/mpra_griesemer/utils\") \n",
    "\n",
    "from models import *\n",
    "from misc import dotdict\n",
    "from misc import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e82215c-3d72-4985-acbf-fd521ff920d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/s/project/mll/sergey/effect_prediction/MLM/griesemer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62141475-833c-4454-9c27-137e8d7686f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_params = dotdict({})\n",
    "\n",
    "input_params.cell_type = 'HEK293FT' #HMEC,HEK293FT,HEPG2,K562,GM12878,SKNSH\n",
    "\n",
    "input_params.model = 'griesemer' #embedding name, can be \"MLM\" \"word2vec\" \"griesemer\" or \"Nmers\" where N is an integer\n",
    "\n",
    "input_params.output_dir = './test' #output folder\n",
    "\n",
    "input_params.N_trials = 1000 #number of optuna trials\n",
    "input_params.keep_first = True #perform hpp search only at the first split, then use these hyperparameters\n",
    "\n",
    "input_params.N_splits = 3 #number of GroupShuffleSplits\n",
    "input_params.N_CVsplits = 5 #number of CV splits for hyperparameter search\n",
    "input_params.seed = 1 #seed fot GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b876caad-6e6f-46b4-a7f4-a24323af5bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpra_df = pd.read_csv(data_dir + 'mpra_df.tsv', sep='\\t') #sequence info\n",
    "\n",
    "mlm_embeddings = np.load(data_dir + \"embeddings/seq_len_5000/embeddings.npy\") #masked language model embeddings\n",
    "\n",
    "#Data Cleaning\n",
    "# Take only SNP mutations\n",
    "# Remove nan values in Expression column\n",
    "\n",
    "is_snp = mpra_df.ref_allele.str.len() == mpra_df.alt_allele.str.len()\n",
    "\n",
    "flt = mpra_df[f'log2FoldChange_Skew_{input_params.cell_type}'].isna()  | (~is_snp) | (mpra_df.stop_codon_dist>5000) #| mpra_df.oligo_id.str.contains('_ref$')\n",
    "\n",
    "mpra_df = mpra_df[~flt]\n",
    "mlm_embeddings = mlm_embeddings[~flt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cceb1dd-9621-45a6-8e4a-170c7f3d4542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Expression column to float\n",
    "\n",
    "mpra_df['Expression'] = mpra_df.apply(lambda x: x[f'log2FoldChange_Alt_{input_params.cell_type}'] if x.oligo_id.endswith('_alt') else x[f'log2FoldChange_Ref_{input_params.cell_type}'], axis=1)   \n",
    "mpra_df.Expression = mpra_df.Expression.apply(lambda x:x.replace(',','.') if type(x)==str else x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ca9f16-a4a4-49fd-a1a5-6a32e1b43a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if input_params.model=='MLM':\n",
    "\n",
    "    X = mlm_embeddings\n",
    "\n",
    "elif 'mers' in input_params.model:\n",
    "    \n",
    "    k = int(input_params.model[0])\n",
    "        \n",
    "    kmerizer = Kmerizer(k=k)\n",
    "    X = np.stack(mpra_df.seq.apply(lambda x: kmerizer.kmerize(x))) \n",
    "        \n",
    "elif input_params.model=='word2vec':\n",
    "        \n",
    "    X = word2vec_model(mpra_df)\n",
    "\n",
    "elif input_params.model=='griesemer':\n",
    "        \n",
    "    X = minseq_model(mpra_df)\n",
    "\n",
    "X = np.hstack((X,np.expand_dims(mpra_df.min_free_energy.values,axis=1)))\n",
    "\n",
    "y = mpra_df['Expression'].values\n",
    "groups = mpra_df['group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc5beaf-d2ee-45ad-a40f-309609edff82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hpp_search(X,y,groups,cv_splits = 5):\n",
    "    \n",
    "    '''\n",
    "    Perform Hyperparameter Search using OPTUNA Bayesian Optimisation strategy\n",
    "    \n",
    "    The bets hyperparameters should maximize coefficient of determination (R2)\n",
    "    \n",
    "    The hyperparameter range should first be adjused with grid search to make the BO algorithm converge in reasonable time\n",
    "    '''\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        p_dropout = trial.suggest_float(\"p_dropout\", 0., 0.9, step=0.1)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 20, log=True)\n",
    "        hidden_layer_sizes = trial.suggest_categorical(\"hidden_layer_sizes\", [(32,16,8,),(64,32,16,),(128,64,32,)])\n",
    "\n",
    "        clf = MLPRegressor(p_dropout=p_dropout, weight_decay=weight_decay, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "        pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),clf)\n",
    "\n",
    "        cv_score = sklearn.model_selection.cross_val_score(pipe, X, y, groups=groups, \n",
    "                     cv = sklearn.model_selection.GroupKFold(n_splits = cv_splits), scoring = 'r2', n_jobs = -1)\n",
    "        \n",
    "        av_score = cv_score.mean()\n",
    "        \n",
    "        return av_score\n",
    "    \n",
    "    study = optuna.create_study(direction = \"maximize\")\n",
    "\n",
    "    study.optimize(objective, n_trials = input_params.N_trials)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cd15461-1efb-4ad0-b8c5-f11efba5760a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "input_params.N_splits = 100\n",
    "\n",
    "\n",
    "cv_res = np.zeros((input_params.N_splits,len(y))) #predictions for each point in each split\n",
    "cv_res[:] = np.NaN \n",
    "\n",
    "cv_scores = [] #scores and best hyperparameters for each split\n",
    "\n",
    "\n",
    "gss = sklearn.model_selection.GroupShuffleSplit(n_splits=input_params.N_splits, train_size=.9, random_state = input_params.seed) \n",
    "\n",
    "for round_idx, (train_idx, test_idx) in enumerate(gss.split(X, y, groups)):\n",
    "    \n",
    "        print(round_idx)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = X[train_idx,:],X[test_idx,:],y[train_idx],y[test_idx]\n",
    "        \n",
    "        #if round_idx==0 or input_params.keep_first==False:\n",
    "            #perform only ones if input_params.keep_first==True\n",
    "        #    best_hpp = hpp_search(X_train,y_train,groups[train_idx],cv_splits = input_params.N_CVsplits)\n",
    "        \n",
    "        best_hpp = {'p_dropout':0.4,'weight_decay':5.5e-5, 'hidden_layer_sizes':(32,16,8)}\n",
    "        pipe = sklearn.pipeline.make_pipeline(sklearn.preprocessing.StandardScaler(),\n",
    "                                              MLPRegressor(**best_hpp))\n",
    "\n",
    "        pipe.fit(X_train,y_train)\n",
    "                    \n",
    "        y_pred = pipe.predict(X_test) \n",
    "        \n",
    "        cv_res[round_idx,test_idx] = y_pred\n",
    "        \n",
    "        cv_scores.append({'round':round_idx,'r2':sklearn.metrics.r2_score(y_test,y_pred)}|best_hpp)\n",
    "        \n",
    "cv_scores = pd.DataFrame(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81c562f3-35fc-4e28-8900-ba7f5508b40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07373225578115418"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.r2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33c8ba-5c3a-49b2-ac80-ee3598ad66d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(input_params.output_dir, exist_ok=True) #make output dir\n",
    "\n",
    "cv_scores.to_csv(input_params.output_dir + '/cv_scores.tsv', sep='\\t', index=None) #save scores\n",
    "\n",
    "with open(input_params.output_dir + '/cv_res.npy', 'wb') as f:\n",
    "    np.save(f, cv_res) #save predictions at each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b490b-5b1e-473c-82c8-7fb445c1cbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-svilov-spade]",
   "language": "python",
   "name": "conda-env-miniconda3-svilov-spade-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
