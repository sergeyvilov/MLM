{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae43e306-e5f1-4831-bb06-cecdb288fd12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import pysam\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be2f56b-e9fb-4abc-9339-a335bc412afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from encoding_utils import sequence_encoders\n",
    "\n",
    "import helpers.train_eval as train_eval    #train and evaluation\n",
    "import helpers.misc as misc                #miscellaneous functions\n",
    "from helpers.metrics import MaskedAccuracy\n",
    "\n",
    "from models.spec_dss import DSSResNet, DSSResNetEmb, SpecAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597bf5fb-c432-4eec-93da-17d6f10af4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, fasta_fa, seq_df, transform):\n",
    "        \n",
    "        self.fasta = pysam.FastaFile(fasta_fa)\n",
    "        \n",
    "        self.seq_df = seq_df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.seq_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        seq = self.fasta.fetch(seq_df.iloc[idx].seq_name).upper()\n",
    "                \n",
    "        species_label = seq_df.iloc[idx].species_label\n",
    "                \n",
    "        masked_sequence, target_labels_masked, target_labels, mask, _ = self.transform(seq, motifs = {})\n",
    "        \n",
    "        masked_sequence = (masked_sequence, species_label)\n",
    "        \n",
    "        return masked_sequence, target_labels_masked, target_labels\n",
    "    \n",
    "    def close(self):\n",
    "        self.fasta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b717766-416d-4f5d-96d2-9e8e2051e704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUDA device: GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('\\nCUDA device: GPU\\n')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('\\nCUDA device: CPU\\n')\n",
    "    #raise Exception('CUDA is not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1958cd83-205c-4a97-9852-08ab25b458ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57f907e3-c581-41a5-80d1-034c93d2917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = misc.dotdict({})\n",
    "\n",
    "input_params.fasta = '/s/project/mll/sergey/effect_prediction/MLM/fasta/240_mammals/240_mammals.shuffled.fa'\n",
    "input_params.species_list = '/s/project/mll/sergey/effect_prediction/MLM/fasta/240_mammals/240_species.txt'\n",
    "\n",
    "input_params.tot_epochs = 50\n",
    "\n",
    "input_params.output_dir = './test'\n",
    "\n",
    "input_params.train = True\n",
    "input_params.val_fraction = 0.1\n",
    "\n",
    "input_params.train_splits = 4\n",
    "\n",
    "input_params.save_at = []\n",
    "input_params.validate_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a3e0f3-6619-4616-bd26-a0ef7a5bbd8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_df = pd.read_csv(input_params.fasta + '.fai', header=None, sep='\\t', usecols=[0], names=['seq_name'])\n",
    "seq_df['species_name'] = seq_df.seq_name.apply(lambda x:x.split(':')[1])\n",
    "\n",
    "#seq_df['seq_len'] = seq_df.seq_name.apply(lambda x:int(x.split(':')[-1]))\n",
    "#seq_df = seq_df[seq_df.seq_len>60]\n",
    "\n",
    "species_encoding = pd.read_csv(input_params.species_list, header=None).squeeze().to_dict()\n",
    "species_encoding = {species:idx for idx,species in species_encoding.items()}\n",
    "species_encoding['Homo_sapiens'] = species_encoding['Pan_troglodytes']\n",
    "\n",
    "seq_df['species_label'] = seq_df.species_name.map(species_encoding)\n",
    "\n",
    "#seq_df = seq_df.sample(frac = 1., random_state = 1) #DO NOT SHUFFLE, otherwise too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be76939f-fe57-4317-9249-476c4c991c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_df = seq_df.iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b563507-8597-4222-b0a2-f059998243a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_transform = sequence_encoders.SequenceDataEncoder(seq_len = 2000, total_len = 2000, \n",
    "                                                      mask_rate = 0.15, split_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98ce1c8b-d70c-4fe7-ac01-e86fd30a8dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/tmp/l_vilov/ipykernel_3645636/2092836944.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['train_fold'] = train_fold[:N_train]\n"
     ]
    }
   ],
   "source": [
    "if input_params.train:\n",
    "    \n",
    "    N_train = int(len(seq_df)*(1-input_params.val_fraction))       \n",
    "    train_df, test_df = seq_df.iloc[:N_train], seq_df.iloc[N_train:]\n",
    "                  \n",
    "    train_fold = np.repeat(list(range(input_params.train_splits)),repeats = N_train // input_params.train_splits + 1 )\n",
    "    train_df['train_fold'] = train_fold[:N_train]\n",
    "\n",
    "    train_dataset = SeqDataset(input_params.fasta, train_df, transform = seq_transform)\n",
    "    train_dataloader = DataLoader(dataset = train_dataset, batch_size = 512, num_workers = 16, collate_fn = None, shuffle = None)\n",
    "\n",
    "else:\n",
    "                  \n",
    "    test_df = seq_df\n",
    "                  \n",
    "test_dataset = SeqDataset(input_params.fasta, test_df, transform = seq_transform)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = 512, num_workers = 16, collate_fn = None, shuffle = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad86179c-11e5-4b3b-a389-b8ab1b00bdbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_encoder = SpecAdd(embed = True, encoder = 'label', d_model = 128)\n",
    "\n",
    "model = DSSResNetEmb(d_input = 5, d_output = 5, d_model = 128, n_layers = 4, \n",
    "                     dropout = 0., embed_before = True, species_encoder = species_encoder)\n",
    "\n",
    "model = model.to(device) \n",
    "\n",
    "model_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_params, lr = 1e-4, weight_decay = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec227158-c405-4dc7-8f6a-38a83009d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 0\n",
    "\n",
    "if input_params.model_weight:\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        #load on gpu\n",
    "        model.load_state_dict(torch.load(input_params.model_weight))\n",
    "        if input_params.optimizer_weight:\n",
    "            optimizer.load_state_dict(torch.load(input_params.optimizer_weight))\n",
    "    else:\n",
    "        #load on cpu\n",
    "        model.load_state_dict(torch.load(input_params.model_weight, map_location=torch.device('cpu')))\n",
    "        if input_params.optimizer_weight:\n",
    "            optimizer.load_state_dict(torch.load(input_params.optimizer_weight, map_location=torch.device('cpu')))\n",
    "\n",
    "    last_epoch = int(input_params.model_weight.split('_')[-3]) #infer previous epoch from input_params.model_weight\n",
    "\n",
    "predictions_dir = os.path.join(input_params.output_dir, 'predictions') #dir to save predictions\n",
    "weights_dir = os.path.join(input_params.output_dir, 'weights') #dir to save model weights at save_at epochs\n",
    "\n",
    "if input_params.save_at:\n",
    "    os.makedirs(weights_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f68efaa-d4a6-424f-a169-6d0d9046ec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_to_str(metrics):\n",
    "    loss, total_acc, masked_acc = metrics\n",
    "    return f'loss: {loss:.4}, total acc: {total_acc:.3f}, masked acc: {masked_acc:.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd086013-fd62-4964-8ccc-8b9d928d727d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: Training...\n",
      "using train samples: [0, 847255]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2060b5c050994c4281a7928ad70e50e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ouga/home/ag_gagneur/l_vilov/miniconda3/envs/svilov-spade/lib/python3.10/site-packages/torch/nn/functional.py:1355: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - train, loss: 1.209, total acc: 0.860, masked acc: 0.430\n",
      "EPOCH 1: Validating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768d6c0b093b4694b11371f4a9191797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m input_params\u001b[38;5;241m.\u001b[39mval_fraction\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ( epoch\u001b[38;5;241m==\u001b[39minput_params\u001b[38;5;241m.\u001b[39mtot_epochs \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                             (input_params\u001b[38;5;241m.\u001b[39mvalidate_every \u001b[38;5;129;01mand\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39minput_params\u001b[38;5;241m.\u001b[39mvalidate_every\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Validating...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m             val_metrics, _ \u001b[38;5;241m=\u001b[39m  \u001b[43mtrain_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - validation, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_to_str(val_metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/nasif12/home_if12/l_vilov/workspace/species-aware-DNA-LM/mammals_model/helpers/train_eval.py:91\u001b[0m, in \u001b[0;36mmodel_eval\u001b[0;34m(model, optimizer, dataloader, device, save_embeddings, silent)\u001b[0m\n\u001b[1;32m     88\u001b[0m targets_masked \u001b[38;5;241m=\u001b[39m targets_masked\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     89\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 91\u001b[0m logits, embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, targets_masked)\n\u001b[1;32m     95\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/svilov-spade/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/nasif12/home_if12/l_vilov/workspace/species-aware-DNA-LM/mammals_model/models/spec_dss.py:202\u001b[0m, in \u001b[0;36mDSSResNetEmb.forward\u001b[0;34m(self, x, xs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     z \u001b[38;5;241m=\u001b[39m norm(z\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Apply S4 block: we ignore the state input and output\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m z, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Dropout on the output of the S4 block\u001b[39;00m\n\u001b[1;32m    205\u001b[0m z \u001b[38;5;241m=\u001b[39m dropout(z)\n",
      "File \u001b[0;32m~/miniconda3/envs/svilov-spade/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/nasif12/home_if12/l_vilov/workspace/species-aware-DNA-LM/mammals_model/models/dss.py:432\u001b[0m, in \u001b[0;36mDSS.forward\u001b[0;34m(self, u, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m#print(u.shape)   \u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Compute SS Kernel\u001b[39;00m\n\u001b[1;32m    431\u001b[0m Lk \u001b[38;5;241m=\u001b[39m L \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_kernel_length \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_kernel_length, L)\n\u001b[0;32m--> 432\u001b[0m k, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLk\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (C H Lk) (B C H Lk)\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m#print(k.shape)\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Convolution\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional:\n",
      "File \u001b[0;32m~/miniconda3/envs/svilov-spade/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/nasif12/home_if12/l_vilov/workspace/species-aware-DNA-LM/mammals_model/models/dss.py:318\u001b[0m, in \u001b[0;36mDSSKernel.forward\u001b[0;34m(self, L, state)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# fast softmax using structure of P\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     Lambda_gt_0 \u001b[38;5;241m=\u001b[39m Lambda\u001b[38;5;241m.\u001b[39mreal \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m                                    \u001b[38;5;66;03m# [N]\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Lambda_gt_0\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    320\u001b[0m             P_max \u001b[38;5;241m=\u001b[39m dt_Lambda \u001b[38;5;241m*\u001b[39m (Lambda_gt_0 \u001b[38;5;241m*\u001b[39m (L\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))                \u001b[38;5;66;03m# [H N]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from utils.misc import print    #print function that displays time\n",
    "\n",
    "if input_params.train:\n",
    "\n",
    "    for epoch in range(last_epoch+1, input_params.tot_epochs+1):\n",
    "\n",
    "        print(f'EPOCH {epoch}: Training...')\n",
    "\n",
    "        train_dataset.seq_df = train_df[train_df.train_fold == (epoch-1) % input_params.train_splits]\n",
    "        print(f'using train samples: {list(train_dataset.seq_df.index[[0,-1]])}')\n",
    "\n",
    "        train_metrics = train_eval.model_train(model, optimizer, train_dataloader, device,\n",
    "                            silent = False)\n",
    "\n",
    "        print(f'epoch {epoch} - train, {metrics_to_str(train_metrics)}')\n",
    "\n",
    "        if epoch in input_params.save_at: #save model weights\n",
    "\n",
    "            misc.save_model_weights(model, optimizer, weights_dir, epoch)\n",
    "\n",
    "        if input_params.val_fraction>0 and ( epoch==input_params.tot_epochs or\n",
    "                            (input_params.validate_every and epoch%input_params.validate_every==0)):\n",
    "\n",
    "            print(f'EPOCH {epoch}: Validating...')\n",
    "\n",
    "            val_metrics, _ =  train_eval.model_eval(model, optimizer, test_dataloader, device,\n",
    "                    silent = False)\n",
    "\n",
    "            print(f'epoch {epoch} - validation, {metrics_to_str(val_metrics)}')\n",
    "\n",
    "else:\n",
    "\n",
    "    print(f'EPOCH {last_epoch}: Test/Inference...')\n",
    "\n",
    "    test_metrics, test_embeddings =  train_eval.model_eval(model, optimizer, test_dataloader, device, \n",
    "                                                          save_embeddings = True, silent = False)\n",
    "\n",
    "    print(f'epoch {last_epoch} - test, {metrics_to_str(test_metrics)}')\n",
    "\n",
    "    os.makedirs(predictions_dir, exist_ok = True)\n",
    "\n",
    "    with open(predictions_dir + '/test_embeddings.pickle', 'wb') as f:\n",
    "        pickle.dump(test_embeddings, f)\n",
    "\n",
    "print()\n",
    "print(f'peak GPU memory allocation: {round(torch.cuda.max_memory_allocated(device)/1024/1024)} Mb')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ca5db02-86b6-4c93-bf9b-effe286501ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128, 2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61180398-7442-4459-9b52-6d72d33c3ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2034fd77-483f-4e3e-b6c9-d9d914379cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44971320832"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3db393c6-1244-4e88-b391-060805bbdd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.46423006057739"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9676b72-6f0c-4f59-a079-95dd145b3062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "metric = MaskedAccuracy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8ee544a-815e-45e1-b73c-2c38a3e90fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.tensor([-100,-100,-100], dtype=torch.long)\n",
    "criterion(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "90e99627-7b3d-449b-97bd-43ef895bd371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 128])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[-1].grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2e599704-a76f-47c2-9889-646d9f642349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.6490, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d8c6bd15-cc10-4afc-a2e5-0866a37c84c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itr = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6c67d80a-109d-4b46-b562-807d328981c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3295, grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e7cef21a-7353-42bf-a5ff-b0dc051c0b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 s4_layers.0.kernel.log_dt torch.Size([128, 2]) tensor(2)\n",
      "32 s4_layers.0.kernel.Lambda torch.Size([64, 2]) tensor(2)\n",
      "32 s4_layers.0.kernel.W torch.Size([2, 128, 64, 2]) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "\n",
    "for idx, data in enumerate(train_dataloader):\n",
    "    \n",
    "    \n",
    "\n",
    "    (masked_sequence, species_label), targets_masked, targets = data\n",
    "\n",
    "    logits, embeddings = model(masked_sequence, species_label)\n",
    "\n",
    "\n",
    "    loss = criterion(logits, targets_masked)\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "        print('Loss nan')\n",
    "        break\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #loss.register_hook(lambda grad: print(grad))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "            #if max_abs_grad:\n",
    "            #    torch.nn.utils.clip_grad_value_(model.parameters(), max_abs_grad)\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    for name,param in model.named_parameters():\n",
    "        \n",
    "        if param.isnan().sum():\n",
    "            print(idx,name,param.shape,param.isnan().sum())\n",
    "            f = 1\n",
    "    if f:\n",
    "        break\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "229fd0f6-a314-4881-8830-1f43d1ff3f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 encoder.weight torch.Size([128, 5, 15]) tensor(0)\n",
      "0 encoder.bias torch.Size([128]) tensor(0)\n",
      "0 s4_layers.0.D torch.Size([1, 128]) tensor(0)\n",
      "0 s4_layers.0.kernel.log_dt torch.Size([128, 2]) tensor(0)\n",
      "0 s4_layers.0.kernel.Lambda torch.Size([64, 2]) tensor(0)\n",
      "0 s4_layers.0.kernel.W torch.Size([2, 128, 64, 2]) tensor(0)\n",
      "0 s4_layers.0.output_linear.0.weight torch.Size([256, 128]) tensor(0)\n",
      "0 s4_layers.0.output_linear.0.bias torch.Size([256, 1]) tensor(0)\n",
      "0 s4_layers.1.kernel.log_dt torch.Size([128, 2]) tensor(0)\n",
      "0 s4_layers.1.kernel.Lambda torch.Size([64, 2]) tensor(0)\n",
      "0 s4_layers.1.kernel.W torch.Size([2, 128, 64, 2]) tensor(0)\n",
      "0 norms.0.weight torch.Size([128]) tensor(0)\n",
      "0 norms.0.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.0.conv1.weight torch.Size([128, 128, 7]) tensor(0)\n",
      "0 resnet_layer.0.conv1.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.0.bn1.weight torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.0.bn1.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.0.conv2.weight torch.Size([128, 128, 7]) tensor(0)\n",
      "0 resnet_layer.0.conv2.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.0.bn2.weight torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.0.bn2.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.1.conv1.weight torch.Size([128, 128, 7]) tensor(0)\n",
      "0 resnet_layer.1.conv1.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.1.bn1.weight torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.1.bn1.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.1.conv2.weight torch.Size([128, 128, 7]) tensor(0)\n",
      "0 resnet_layer.1.conv2.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.1.bn2.weight torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.1.bn2.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.2.conv1.weight torch.Size([128, 128, 7]) tensor(0)\n",
      "0 resnet_layer.2.conv1.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.2.bn1.weight torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.2.bn1.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.2.conv2.weight torch.Size([128, 128, 7]) tensor(0)\n",
      "0 resnet_layer.2.conv2.bias torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.2.bn2.weight torch.Size([128]) tensor(0)\n",
      "0 resnet_layer.2.bn2.bias torch.Size([128]) tensor(0)\n",
      "0 species_encoder.species_embedder.weight torch.Size([240, 128]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "\n",
    "for name,param in model.named_parameters():\n",
    "        \n",
    "        if param.grad.max()>1e10:\n",
    "            print(idx,name,param.shape,param.isnan().sum())\n",
    "            f = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "57d93358-7c52-4697-af8b-b015aa34c695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.weight tensor(3.3170e+30)\n",
      "encoder.bias tensor(1.1146e+30)\n",
      "s4_layers.0.D tensor(2.9693e+19)\n",
      "s4_layers.0.kernel.log_dt tensor(7.0755e+31)\n",
      "s4_layers.0.kernel.Lambda tensor(1.8249e+30)\n",
      "s4_layers.0.kernel.W tensor(2.0817e+30)\n",
      "s4_layers.0.output_linear.0.weight tensor(2.3028e+21)\n",
      "s4_layers.0.output_linear.0.bias tensor(1.2498e+20)\n",
      "s4_layers.1.D tensor(146.5361)\n",
      "s4_layers.1.kernel.log_dt tensor(9.7293e+22)\n",
      "s4_layers.1.kernel.Lambda tensor(3.9747e+20)\n",
      "s4_layers.1.kernel.W tensor(9.7611e+19)\n",
      "s4_layers.1.output_linear.0.weight tensor(3326.9224)\n",
      "s4_layers.1.output_linear.0.bias tensor(415.3416)\n",
      "s4_layers.2.D tensor(0.0226)\n",
      "s4_layers.2.kernel.log_dt tensor(1.7157)\n",
      "s4_layers.2.kernel.Lambda tensor(0.0852)\n",
      "s4_layers.2.kernel.W tensor(0.0082)\n",
      "s4_layers.2.output_linear.0.weight tensor(3386.7385)\n",
      "s4_layers.2.output_linear.0.bias tensor(561.5174)\n",
      "s4_layers.3.D tensor(321.0021)\n",
      "s4_layers.3.kernel.log_dt tensor(12325.0898)\n",
      "s4_layers.3.kernel.Lambda tensor(4139.0215)\n",
      "s4_layers.3.kernel.W tensor(314.6330)\n",
      "s4_layers.3.output_linear.0.weight tensor(0.2136)\n",
      "s4_layers.3.output_linear.0.bias tensor(0.0158)\n",
      "norms.0.weight tensor(7.6660e+20)\n",
      "norms.0.bias tensor(3.0430e+20)\n",
      "norms.1.weight tensor(1278.6000)\n",
      "norms.1.bias tensor(859.3845)\n",
      "norms.2.weight tensor(1547.0991)\n",
      "norms.2.bias tensor(988.6155)\n",
      "norms.3.weight tensor(0.0673)\n",
      "norms.3.bias tensor(0.0252)\n",
      "decoder.weight tensor(0.4910)\n",
      "decoder.bias tensor(0.2090)\n",
      "resnet_layer.0.conv1.weight tensor(1.5989e+31)\n",
      "resnet_layer.0.conv1.bias tensor(7.3504e+24)\n",
      "resnet_layer.0.bn1.weight tensor(1.0273e+30)\n",
      "resnet_layer.0.bn1.bias tensor(7.0964e+29)\n",
      "resnet_layer.0.conv2.weight tensor(4.5550e+30)\n",
      "resnet_layer.0.conv2.bias tensor(9.8078e+23)\n",
      "resnet_layer.0.bn2.weight tensor(7.6535e+29)\n",
      "resnet_layer.0.bn2.bias tensor(5.2729e+29)\n",
      "resnet_layer.1.conv1.weight tensor(4.3276e+30)\n",
      "resnet_layer.1.conv1.bias tensor(1.3057e+24)\n",
      "resnet_layer.1.bn1.weight tensor(6.5049e+29)\n",
      "resnet_layer.1.bn1.bias tensor(4.8014e+29)\n",
      "resnet_layer.1.conv2.weight tensor(7.0903e+30)\n",
      "resnet_layer.1.conv2.bias tensor(6.6674e+23)\n",
      "resnet_layer.1.bn2.weight tensor(8.2007e+29)\n",
      "resnet_layer.1.bn2.bias tensor(2.3273e+29)\n",
      "resnet_layer.2.conv1.weight tensor(2.9183e+30)\n",
      "resnet_layer.2.conv1.bias tensor(3.0341e+23)\n",
      "resnet_layer.2.bn1.weight tensor(6.0659e+29)\n",
      "resnet_layer.2.bn1.bias tensor(2.8376e+29)\n",
      "resnet_layer.2.conv2.weight tensor(8.8405e+30)\n",
      "resnet_layer.2.conv2.bias tensor(8.2670e+13)\n",
      "resnet_layer.2.bn2.weight tensor(6.2293e+29)\n",
      "resnet_layer.2.bn2.bias tensor(2.4675e+28)\n",
      "species_encoder.species_embedder.weight tensor(1.1146e+30)\n"
     ]
    }
   ],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name, param.grad.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ed261b50-517e-4c5f-955e-1837e41d5d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.4045e+29, -1.2555e+30],\n",
       "        [ 6.1969e+30, -1.8450e+31],\n",
       "        [-9.0364e+30, -3.4811e+30],\n",
       "        [ 1.6769e+32,  5.5701e+31],\n",
       "        [-4.0765e+30, -3.2897e+31],\n",
       "        [-2.4014e+32, -1.0221e+32],\n",
       "        [-7.3908e+31, -6.7461e+31],\n",
       "        [-1.3097e+32, -1.5515e+32],\n",
       "        [ 7.0436e+31,  3.6052e+31],\n",
       "        [-3.8711e+32,  1.7960e+32],\n",
       "        [-4.5004e+31, -1.9284e+32],\n",
       "        [-1.1951e+32,  3.9861e+32],\n",
       "        [ 9.5394e+31, -3.6152e+31],\n",
       "        [-1.8462e+32, -1.8041e+33],\n",
       "        [-6.7417e+31,  4.2997e+31],\n",
       "        [ 2.2285e+32,  1.3209e+31],\n",
       "        [-6.3038e+31,  3.3885e+31],\n",
       "        [ 1.5946e+32, -1.2147e+32],\n",
       "        [-1.0125e+33,  4.7673e+32],\n",
       "        [-7.3206e+31,  1.6535e+32],\n",
       "        [-2.7117e+32,  2.6849e+32],\n",
       "        [-4.5600e+31, -6.9701e+31],\n",
       "        [ 3.9817e+32,  7.6175e+31],\n",
       "        [ 4.6965e+32,  1.9915e+32],\n",
       "        [-1.2158e+31, -3.4869e+31],\n",
       "        [-7.9421e+31,  1.9504e+32],\n",
       "        [ 7.8557e+31, -1.7855e+32],\n",
       "        [ 1.1458e+32,  2.1956e+32],\n",
       "        [-2.5009e+32,  4.9811e+32],\n",
       "        [-2.2592e+32, -3.8547e+31],\n",
       "        [-1.5769e+32, -3.0889e+32],\n",
       "        [ 1.2757e+32,  6.0058e+32],\n",
       "        [ 3.5246e+32,  1.7379e+32],\n",
       "        [-1.0573e+32, -3.8237e+32],\n",
       "        [-1.9291e+33,  8.0309e+33],\n",
       "        [ 2.7990e+32, -6.5735e+32],\n",
       "        [ 1.3353e+33,  3.5866e+32],\n",
       "        [-2.2544e+32,  2.1510e+32],\n",
       "        [ 5.5953e+32, -4.2265e+32],\n",
       "        [ 6.7812e+32,  2.0605e+32],\n",
       "        [ 2.0441e+32,  1.2870e+32],\n",
       "        [ 5.7990e+32, -3.1082e+32],\n",
       "        [ 2.0659e+32, -5.0820e+32],\n",
       "        [-2.5809e+32, -5.1303e+32],\n",
       "        [ 6.7511e+33,  1.7312e+33],\n",
       "        [-2.3600e+33, -2.3003e+33],\n",
       "        [-1.7157e+33, -9.6116e+32],\n",
       "        [-1.7795e+33, -6.0051e+32],\n",
       "        [-1.2961e+33, -1.0827e+33],\n",
       "        [ 9.8699e+32, -1.4886e+33],\n",
       "        [-5.3287e+32,  3.4815e+31],\n",
       "        [-1.8048e+33,  2.5055e+33],\n",
       "        [-3.7992e+32,  7.2556e+32],\n",
       "        [-1.1949e+31,  2.1532e+33],\n",
       "        [ 3.5246e+33,  2.7011e+33],\n",
       "        [ 9.3747e+32,  1.8198e+33],\n",
       "        [-2.0706e+33,  8.6958e+32],\n",
       "        [ 8.4085e+32, -3.0971e+32],\n",
       "        [-1.0018e+33, -4.1942e+33],\n",
       "        [-9.2238e+32, -9.2709e+32],\n",
       "        [ 2.2152e+33,  5.2354e+33],\n",
       "        [ 6.6036e+31, -6.4770e+33],\n",
       "        [ 2.9395e+33, -1.4386e+34],\n",
       "        [-3.3729e+34, -4.3530e+32]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.s4_layers[0].kernel.Lambda.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a23c53ea-8c16-449c-847f-9b3a9d1450bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSSResNetEmb(\n",
      "  (encoder): Conv1d(5, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "  (s4_layers): ModuleList(\n",
      "    (0-3): 4 x DSS(\n",
      "      (kernel): DSSKernel()\n",
      "      (activation): GELU(approximate='none')\n",
      "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "      (output_linear): Sequential(\n",
      "        (0): TransposedLinear()\n",
      "        (1): GLU(dim=-2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-3): 4 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (dropouts): ModuleList(\n",
      "    (0-3): 4 x Dropout2d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Conv1d(128, 5, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "  (resnet_layer): Sequential(\n",
      "    (0): L1Block(\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer): Sequential(\n",
      "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): L1Block(\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer): Sequential(\n",
      "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): L1Block(\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer): Sequential(\n",
      "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (species_encoder): SpecAdd(\n",
      "    (species_embedder): Embedding(240, 128)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b81ef-05e4-4b35-aeee-cddbdc86855d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "        metric(preds, targets_masked).detach() # compute only on masked nucleotides\n",
    "        metric(preds, targets).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "36759b68-b3e4-49f4-8b7f-77cd1b5cde69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 52,  14, 205, 181])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6689f7-2379-4428-8258-fbeadb6508c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasta = pysam.FastaFile(train_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6890584-f7ab-4c4e-a86e-059a36f0f2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq = fasta.fetch('ENST00000318911.5_utr3_6_0_chr8_144097337_f:Acinonyx_jubatus:LLWD01000002.1:189')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985aae3-da49-4be6-9071-ee0cc99143a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq = 'CCCTGCCCAACGTCTGCTTGCCGTCTTGCCTGAACAGGCCCGCAAGCCAAGGAGCCACCCTGGACCTGTTCAGGCCTCAGCTGGCCCGCTTGGCCAAGCTCCTCTTTCTTTGGGACAAGAGGGAAAGGGGCAAGAGACCAGGTTCTAGCTCCAGATCCTTCAGCACCCATCATGGAAATAAATTAAGTT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0d624-1ce8-4c63-8594-855ddd01c4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = sequence_encoders.SequenceDataEncoder(seq_len=200,\n",
    "                total_len=200,\n",
    "                mask_rate=0.15,\n",
    "                split_mask=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea92835-cadd-4827-bd50-eaa08bd2554d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_sequence, target_labels_masked, target_labels, mask, motif_mask = encoder.__call__(seq, motifs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130583e-0a92-4b3a-974d-7db28e8466a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_labels_masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0394a-0fca-44dc-bb4c-ef4e92f5f08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_labels_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cbfcb-dfa4-4ab1-8055-f3ecf6f6f4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.sequence_operations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec57f64-8650-409b-9918-0e57e92c2116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_labels, seq_one_hot = one_hot_encode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a730e-1250-481f-9709-d38324af8925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_seq, mask = random_masking(seq_one_hot,\n",
    "                            mask_rate=0.15,\n",
    "                            split_mask=False,\n",
    "                            frame=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174afb64-b8fc-4dee-8449-207ae932532c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98947c0-6347-46f8-8ce3-5b88fdda4500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-svilov-spade]",
   "language": "python",
   "name": "conda-env-miniconda3-svilov-spade-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
