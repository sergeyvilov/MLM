{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adacf151-a8aa-437a-9cb5-11e07efc1ed6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Analyse MAF alignment of stop codons for each transcript\n",
    "\n",
    "For each transcript:\n",
    "\n",
    "* take species whose stop codon is contiguous and matches the human stop codon\n",
    "* if MAF alignment strand (species strand) is positive, 3'UTR can be to the right of the stop codon (positive gene) or to the left (negative gene). In the latter case, should be reverse complemented\n",
    "* if MAF alignment strand is negative, take original sequence for negative genes and reverse complement for positive genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed93b429-ea14-4a8a-86bb-9d4dabb2abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f86e333-f144-4dfe-8d2f-607b09e7ea7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clean human 3'UTR, see GRCh38_3_prime_UTR_clean.ipynb\n",
    "\n",
    "human_utr_df = pd.read_csv('/s/project/mll/sergey/MLM/UTR_coords/GRCh38_3_prime_UTR_clean.bed', sep='\\t', \n",
    "                       names = ['chrom','human_UTR_start','human_UTR_end','UTR_ID',\n",
    "                               'score','strand','transcript_ID','canonical','HGNC_Symbol','UTR_len']).set_index('UTR_ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9334bbb-0831-4571-8614-e92ba3e13b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/s/project/mll/sergey/MLM/exp/600_way_stop_codon/maf/' #stop codon alignment for each transcript, see hal_to_maf_array.sh\n",
    "\n",
    "stop_codon_mafs = [p for p in Path(data_dir).rglob(\"*.maf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c3f1c8c-337f-4612-8f7f-8274e2ab41fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_msa(maf_file):\n",
    "    \n",
    "    '''\n",
    "    Get sequences with contiguous alignment around human start codon for a given transcript\n",
    "    '''\n",
    "\n",
    "    msa = defaultdict(dict)\n",
    "\n",
    "    contig_lenghts = dict() #total lengths of contigs for different species\n",
    "\n",
    "    first_block = 1 #current MSA block is the first in the file\n",
    "\n",
    "    with open(maf_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('s'):\n",
    "                _, species_contig, start, seq_len, strand, contig_length, seq = line.split()\n",
    "                start, seq_len = int(start), int(seq_len)\n",
    "                if first_block:\n",
    "                    msa[species_contig]['seq'] = seq\n",
    "                    msa[species_contig]['next_pos'] = start+seq_len #expected start position in the next alignment block\n",
    "                    msa[species_contig]['strand'] = strand\n",
    "                    contig_lenghts[species_contig] = int(contig_length)\n",
    "                elif species_contig in msa.keys() and msa[species_contig]['next_pos'] == start:\n",
    "                    #extend sequence only if the same contig is already seen in the 1st block, i.e. alignment is contiguous\n",
    "                    msa[species_contig]['seq'] += seq\n",
    "                    msa[species_contig]['next_pos'] = start+seq_len\n",
    "            elif len(msa)>0:\n",
    "                first_block = 0 \n",
    "            \n",
    "    return msa,contig_lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5927eb32-f52b-4d91-92a2-e7274bd7bc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_utr_coords(UTR_ID,msa,contig_lenghts):\n",
    "    \n",
    "    '''\n",
    "    Get 3'UTR coordinates for all species\n",
    "    the UTR length is the human UTR length\n",
    "    start (end) of UTR corresponds to end (start) of the stop codon\n",
    "    '''\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    if UTR_ID not in human_utr_df.index:\n",
    "        return res\n",
    "\n",
    "    gene_strand = human_utr_df.loc[UTR_ID].strand\n",
    "    UTR_len = human_utr_df.loc[UTR_ID].UTR_len\n",
    "    HGNC_Symbol = human_utr_df.loc[UTR_ID].HGNC_Symbol\n",
    "\n",
    "    def is_stop_codon(seq):\n",
    "        if gene_strand=='+':\n",
    "            return seq.upper() in ['TAG','TAA','TGA']\n",
    "        else:\n",
    "            return seq.upper() in ['CTA','TTA','TCA']\n",
    "\n",
    "    for k in msa.keys():\n",
    "        if k.startswith('Homo_sapiens'):\n",
    "            homo_sapiens_key = k\n",
    "            break\n",
    "                    \n",
    "    if not is_stop_codon(msa[homo_sapiens_key]['seq'].upper()):\n",
    "        #if human stop codon isn't correct, return empty array\n",
    "        return res\n",
    "\n",
    "    for species_contig,v in msa.items():\n",
    "        species_seq, species_strand = v['seq'], v['strand']\n",
    "        if species_seq.upper()==msa[homo_sapiens_key]['seq'].upper(): #if stop codon is the same as for human\n",
    "            species, *contig = species_contig.split('.')\n",
    "            contig = '.'.join(contig)\n",
    "            if gene_strand=='+':\n",
    "                if species_strand=='+':\n",
    "                    utr_start = v['next_pos']\n",
    "                    utr_end = min(v['next_pos'] + UTR_len,contig_lenghts[species_contig])\n",
    "                else:\n",
    "                    utr_end = contig_lenghts[species_contig]-v['next_pos']\n",
    "                    utr_start = max(utr_end - UTR_len,0)\n",
    "                    #needs reverse complement after FASTA extraction\n",
    "            else:\n",
    "                if species_strand=='+':\n",
    "                    utr_end = v['next_pos'] - 3\n",
    "                    utr_start = max(utr_end - UTR_len,0)\n",
    "                    #needs reverse complement after FASTA extraction\n",
    "                else:\n",
    "                    utr_start = contig_lenghts[species_contig]-v['next_pos'] + 3\n",
    "                    utr_end = min(utr_start + UTR_len,contig_lenghts[species_contig])\n",
    "\n",
    "            res.append((HGNC_Symbol,UTR_ID,UTR_len,gene_strand,species,contig,utr_start,utr_end,species_strand))\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc720e5-0f96-499f-8e9b-8aeb08b80313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/20222 files done\n",
      "200/20222 files done\n",
      "300/20222 files done\n",
      "400/20222 files done\n",
      "500/20222 files done\n",
      "600/20222 files done\n",
      "700/20222 files done\n",
      "800/20222 files done\n",
      "900/20222 files done\n",
      "1000/20222 files done\n",
      "1100/20222 files done\n",
      "1200/20222 files done\n",
      "1300/20222 files done\n",
      "1400/20222 files done\n",
      "1500/20222 files done\n",
      "1600/20222 files done\n",
      "1700/20222 files done\n",
      "1800/20222 files done\n",
      "1900/20222 files done\n",
      "2000/20222 files done\n",
      "2100/20222 files done\n",
      "2200/20222 files done\n",
      "2300/20222 files done\n",
      "2400/20222 files done\n",
      "2500/20222 files done\n",
      "2600/20222 files done\n",
      "2700/20222 files done\n",
      "2800/20222 files done\n",
      "2900/20222 files done\n",
      "3000/20222 files done\n",
      "3100/20222 files done\n",
      "3200/20222 files done\n",
      "3300/20222 files done\n",
      "3400/20222 files done\n",
      "3500/20222 files done\n",
      "3600/20222 files done\n",
      "3700/20222 files done\n",
      "3800/20222 files done\n",
      "3900/20222 files done\n",
      "4000/20222 files done\n",
      "4100/20222 files done\n",
      "4200/20222 files done\n",
      "4300/20222 files done\n",
      "4400/20222 files done\n",
      "4500/20222 files done\n",
      "4600/20222 files done\n",
      "4700/20222 files done\n",
      "4800/20222 files done\n",
      "4900/20222 files done\n",
      "5000/20222 files done\n",
      "5100/20222 files done\n",
      "5200/20222 files done\n",
      "5300/20222 files done\n",
      "5400/20222 files done\n",
      "5500/20222 files done\n",
      "5600/20222 files done\n",
      "5700/20222 files done\n",
      "5800/20222 files done\n",
      "5900/20222 files done\n",
      "6000/20222 files done\n",
      "6100/20222 files done\n",
      "6200/20222 files done\n",
      "6300/20222 files done\n",
      "6400/20222 files done\n",
      "6500/20222 files done\n",
      "6600/20222 files done\n",
      "6700/20222 files done\n",
      "6800/20222 files done\n",
      "6900/20222 files done\n",
      "7000/20222 files done\n",
      "7100/20222 files done\n",
      "7200/20222 files done\n",
      "7300/20222 files done\n",
      "7400/20222 files done\n",
      "7500/20222 files done\n",
      "7600/20222 files done\n",
      "7700/20222 files done\n",
      "7800/20222 files done\n",
      "7900/20222 files done\n",
      "8000/20222 files done\n",
      "8100/20222 files done\n",
      "8200/20222 files done\n",
      "8300/20222 files done\n",
      "8400/20222 files done\n",
      "8500/20222 files done\n",
      "8600/20222 files done\n",
      "8700/20222 files done\n",
      "8800/20222 files done\n",
      "8900/20222 files done\n",
      "9000/20222 files done\n",
      "9100/20222 files done\n",
      "9200/20222 files done\n",
      "9300/20222 files done\n",
      "9400/20222 files done\n",
      "9500/20222 files done\n",
      "9600/20222 files done\n",
      "9700/20222 files done\n",
      "9800/20222 files done\n",
      "9900/20222 files done\n",
      "10000/20222 files done\n",
      "10100/20222 files done\n",
      "10200/20222 files done\n",
      "10300/20222 files done\n",
      "10400/20222 files done\n",
      "10500/20222 files done\n",
      "10600/20222 files done\n",
      "10700/20222 files done\n",
      "10800/20222 files done\n",
      "10900/20222 files done\n",
      "11000/20222 files done\n",
      "11100/20222 files done\n",
      "11200/20222 files done\n",
      "11300/20222 files done\n",
      "11400/20222 files done\n",
      "11500/20222 files done\n",
      "11600/20222 files done\n",
      "11700/20222 files done\n",
      "11800/20222 files done\n",
      "11900/20222 files done\n",
      "12000/20222 files done\n",
      "12100/20222 files done\n",
      "12200/20222 files done\n",
      "12300/20222 files done\n",
      "12400/20222 files done\n",
      "12500/20222 files done\n",
      "12600/20222 files done\n",
      "12700/20222 files done\n",
      "12800/20222 files done\n",
      "12900/20222 files done\n",
      "13000/20222 files done\n",
      "13100/20222 files done\n",
      "13200/20222 files done\n",
      "13300/20222 files done\n",
      "13400/20222 files done\n",
      "13500/20222 files done\n",
      "13600/20222 files done\n",
      "13700/20222 files done\n",
      "13800/20222 files done\n",
      "13900/20222 files done\n",
      "14000/20222 files done\n",
      "14100/20222 files done\n",
      "14200/20222 files done\n",
      "14300/20222 files done\n",
      "14400/20222 files done\n",
      "14500/20222 files done\n",
      "14600/20222 files done\n",
      "14700/20222 files done\n",
      "14800/20222 files done\n",
      "14900/20222 files done\n",
      "15000/20222 files done\n",
      "15100/20222 files done\n",
      "15200/20222 files done\n",
      "15300/20222 files done\n",
      "15400/20222 files done\n",
      "15500/20222 files done\n",
      "15600/20222 files done\n",
      "15700/20222 files done\n",
      "15800/20222 files done\n",
      "15900/20222 files done\n",
      "16000/20222 files done\n",
      "16100/20222 files done\n",
      "16200/20222 files done\n",
      "16300/20222 files done\n",
      "16400/20222 files done\n",
      "16500/20222 files done\n",
      "16600/20222 files done\n",
      "16700/20222 files done\n",
      "16800/20222 files done\n",
      "16900/20222 files done\n",
      "17000/20222 files done\n",
      "17100/20222 files done\n",
      "17200/20222 files done\n",
      "17300/20222 files done\n",
      "17400/20222 files done\n",
      "17500/20222 files done\n",
      "17600/20222 files done\n",
      "17700/20222 files done\n",
      "17800/20222 files done\n",
      "17900/20222 files done\n",
      "18000/20222 files done\n",
      "18100/20222 files done\n",
      "18200/20222 files done\n",
      "18300/20222 files done\n",
      "18400/20222 files done\n",
      "18500/20222 files done\n",
      "18600/20222 files done\n",
      "18700/20222 files done\n",
      "18800/20222 files done\n",
      "18900/20222 files done\n",
      "19000/20222 files done\n",
      "19100/20222 files done\n",
      "19200/20222 files done\n",
      "19300/20222 files done\n",
      "19400/20222 files done\n",
      "19500/20222 files done\n",
      "19600/20222 files done\n",
      "19700/20222 files done\n",
      "19800/20222 files done\n",
      "19900/20222 files done\n",
      "20000/20222 files done\n",
      "20100/20222 files done\n",
      "20200/20222 files done\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for maf_idx, maf_path in enumerate(stop_codon_mafs):\n",
    "    \n",
    "    #loop over all stop codon MAF files and extract 3'UTR coordinates for all species\n",
    "    \n",
    "    #maf_file = 'ENST00000698999.1_utr3_4_0_chrX_135775852_r.maf'\n",
    "            \n",
    "    msa,contig_lenghts = extract_msa(maf_path)\n",
    "    \n",
    "    UTR_ID = maf_path.stem\n",
    "    \n",
    "    subtable = get_utr_coords(UTR_ID, msa,contig_lenghts)\n",
    "    \n",
    "    res.extend(subtable)\n",
    "    \n",
    "    if (maf_idx+1)%100==0:\n",
    "        print(f'{maf_idx+1}/{len(stop_codon_mafs)} files done')\n",
    "        \n",
    "    #if maf_idx+1==1000:\n",
    "    #    break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9f27a48-8a6b-4ad3-b78b-775ce4826918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res,\n",
    "             columns=['HGNC_Symbol','human_UTR_ID','human_UTR_len','human_transcript_strand','species','contig','3_prime_UTR_start','3_prime_UTR_end','MAF_strand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbc8762a-f9ee-48d1-896c-ab3d53a47cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['species','contig','3_prime_UTR_start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4027d194-6e0b-49e5-b302-f8ca78044f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.to_csv('/s/project/mll/sergey/MLM/UTR_coords/GRCh38_3_prime_UTR_all_species.tsv', sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584c206-099e-4602-9183-af4879df4716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b97e9c2d-d0e9-44f4-992f-3b300c73a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/s/project/mll/sergey/MLM/UTR_coords/GRCh38_3_prime_UTR_all_species.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2fc2d3-def9-41b0-8a9f-6dbc609be379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.048007100820541"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)*2000/1024**3 #dataset size in Gb if 2000bp are used for each UTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4ffa16-86af-437e-8f61-b4fc3e9057ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.585104384459555"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.human_UTR_len.sum()/1024**3 #dataset size in Gb if for each UTR the full length is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce94d71-5fe4-431f-842e-f4141d49aa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-svilov-spade]",
   "language": "python",
   "name": "conda-env-miniconda3-svilov-spade-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
